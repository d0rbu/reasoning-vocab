# Model configuration for Qwen3-0.6B with optional reasoning vocabulary

# Model identifier from HuggingFace
name: "Qwen/Qwen3-0.6B"

# Reasoning vocabulary settings
reasoning_vocab_size: 0  # 0 means baseline (no reasoning vocab), set to >0 to enable
reasoning_start_token: "<think>"
reasoning_end_token: "</think>"

# Model loading arguments
model_kwargs:
  torch_dtype: "bfloat16"  # float32, float16, bfloat16
  trust_remote_code: true
  load_in_8bit: false
  load_in_4bit: false

# Generation arguments
generation_kwargs:
  max_new_tokens: 8192
  temperature: 0.6
  do_sample: true

